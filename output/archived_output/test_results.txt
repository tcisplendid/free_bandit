We want to explore (1)arms with larger confidence interval, (2) arms with smaller mean

Process

UCB-E:
the average regrets are  [202.0, 254.3, 242.4, 242.4, 235.0, 224.6, 224.2, 216.1, 210.8, 209.8]


1. Largest interval:
(1) UCB interval
the average regrets are  [202.0, 84.0, 117.6, 137.5, 151.1, 155.1, 161.7, 164.6, 164.8, 168.5]

(2) UCB-E interval
the average regrets are  [202.0, 83.6, 117.8, 140.7, 150.8, 156.6, 161.4, 163.0, 166.1, 170.1]

2. max(-mean + interval)
(1) UCB
the average regrets are  [202.0, 104.4, 124.1, 146.5, 152.1, 156.7, 164.6, 165.6, 165.3, 164.6]

(2) UCB-E
the average regrets are  [202.0, 133.3, 155.6, 160.0, 155.7, 169.5, 182.0, 183.4, 177.2, 180.7]

3. max(-mean)
the average regrets are  [202.0, 174.3, 176.6, 179.6, 180.4, 181.4, 182.4, 183.4, 180.8, 180.7]

4. max(mean-confidence)
the average regrets are  [202.0, 238.4, 240.5, 242.2, 235.9, 224.6, 224.2, 216.1, 210.8, 210.7]




1. e-greedy
2. only update mean, don't update confidence
3. free pulls as random pulls (pure exploration)
4. distinguish free pull and normal pull in the estimation interval









Sep. 3rd

1. Epsilon greedy

(1) alpha = 0.1, st_dev = 0
k = [0...18]
the average regrets are  [63.26, 26.16, 29.3, 30.27, 31.06, 31.61, 32.13, 31.84, 32.37, 31.84, 34.42, 35.96, 38.48, 40.0, 41.1, 43.64, 42.71, 43.29, 42.54]
0's alpha is 0.1
1's alpha is -0.8
2's alpha is -0.35
3's alpha is -0.19999999999999998
4's alpha is -0.125
5's alpha is -0.07999999999999999
6's alpha is -0.04999999999999999
7's alpha is -0.028571428571428564
8's alpha is -0.012499999999999997
9's alpha is 0.0
10's alpha is 0.010000000000000009
11's alpha is 0.0181818181818182
12's alpha is 0.025000000000000005
13's alpha is 0.030769230769230778
14's alpha is 0.03571428571428571
15's alpha is 0.04000000000000001
16's alpha is 0.04375000000000001
17's alpha is 0.047058823529411764
18's alpha is 0.05000000000000001
the average regrets are  [70.0, 30.0, 33.0, 34.0, 36.0, 35.0, 36.0, 35.0, 36.0, 36.0, 36.0, 50.0, 36.0, 49.0, 42.0, 38.0, 44.0, 51.0, 55.0]
the explore rates are :
[(0.0, 2), (0.0, 2), (0.0, 3), (0.0, 2), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 3), (0.0, 55)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0, 0), (0.0, 1), (0, 0), (0.0, 1), (0.0, 64)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0, 0), (0, 0), (0.0, 64)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0, 0), (0.0, 1), (0.0, 63)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0, 0), (0.0, 63)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0, 0), (0.0, 63)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 2), (0.0, 1), (0.0, 2), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 60)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 62)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 3), (0.0, 2), (0.0, 2), (0.0, 1), (0.0, 58)]
[(0.0, 1), (0.0, 1), (0.0, 2), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 61)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 2), (0.0, 1), (0.0, 61)]
[(0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 3), (0.0, 2), (0.0, 1), (0.0, 59)]
[(0.0, 1), (0.0, 1), (0.0, 2), (0.0, 2), (0.0, 2), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 59)]
[(0.0, 2), (0.0, 1), (0.0, 1), (0.0, 3), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 2), (0.0, 58)]


(2) alpha = 0.2, st_dev = 0
the average regrets are  [163.5, 25.7, 29.7, 30.2, 32.9, 56.8, 83.9, 80.3, 95.1, 98.1, 100.9, 124.4, 114.3, 115.4, 127.9, 120.8, 113.9, 132.4, 147.6]

(3) epsilon = 0.2, st_dev = 0.1
the average regrets are

normal stratgy: noram epsilon greedy: 156.1821311485103

[156.1821311485103, 47.62675797370157, 39.890339046433475, 44.53780739381823, 43.2965428870001,
75.76714810091096, 93.70961083838581, 98.84344459200088, 118.8578135238087,
129.92036725911694, 118.66101022377136, 136.20727938713082, 132.32741859748594, 149.85382286068233, 165.5572913212159, 159.49471088077013, 134.22262676686972, 149.19942321645456, 140.40374242393943]






























1. epsilon greedy
(1) epsilon greedy:
500 trials. Each trial with 170 rounds.

epsilon = 0.2
Normal: epsilon greedy. Free: pure explore.
k=[    infinity     |        1        |       2          |          3        |          4         |         5        |         6         |        7         |         8        |         9         ]
[236.49419823461292, 217.047513060714, 222.41653892881837, 223.42742253732135, 227.39283852217847, 229.78015614309598, 231.08760966881798, 230.83085071169512, 228.8152102467451, 231.208331123288]

Normal: epsilon greedy. Free: always worst.
[239.84238739907332, 231.12156657874567, 230.06032565231166, 230.9848872334609, 234.87815154350687, 227.9815596963287, 233.99365224214503, 235.50942318277038, 232.22968318851406, 233.45691202446892]

Normal: epsilon greedy. Free: always best.
[236.02024495016283, 231.27351061387498, 230.14778517899023, 230.7259147786348, 229.44593914877908, 232.273638146906, 232.1567797588186, 236.8496416013879, 233.6708735973664, 234.87417046906828]

Normal: epsilon greedy. Free: UCB.
[235.39410575644382, 209.01113388307826, 213.73498601707396, 220.26774524375898, 219.44274930676445, 223.9346215340228, 224.3706544430121, 226.88449053551412, 222.8582632329709, 225.41763870713143]

Normal: epsilon greedy. Free: always real worst, which is arm 0.
[235.67705992359456, 231.2923055056658, 229.76818151173222, 236.05812011275813, 231.74832536268735, 233.01430783554747, 227.61932101530337, 234.62975425094257, 228.76672731110753, 233.47842425037646]

Normal: epsilon greedy. Free: always real best, which is arm 8.
[236.3226438893191, 219.8852304534977, 221.75835835379505, 220.01723918686773, 222.02765121784898, 223.30074716322457, 223.83791023879652, 224.03382835013045, 221.766561945135, 224.8021082916053]

Normal: epsilon greedy. Free: always real second best, which is arm 7.
[233.6459349089495, 241.86325271516864, 237.63059165963756, 237.06204361161116, 241.94942968706897, 242.79069518317255, 238.99000242552458, 240.36340943603102, 235.620166205446, 238.23647165002603]

Normal: epsilon greedy. Free: UCB second best.
[213.61, 216.79, 222.03, 222.07, 226.65, 225.56, 227.94, 227.01, 231.29, 238.56]





epsilon = 0.1
Normal: epsilon greedy. Free: pure explore.
[183.76647924636808, 160.4974343158044, 165.7555741756295, 168.79170707687106, 169.2929563851155, 176.2486818869426, 174.2636229368445, 177.72312860527128, 175.3146151786495, 178.20831687958702]

Normal: epsilon greedy. Free: always worst.
[182.9641023429176, 179.348908733977, 181.14649796873698, 179.03972525958986, 177.28384435204916, 188.1425898371493, 184.99639747923845, 180.30559943811343, 181.10348838617787, 182.4446048245974]

Normal: epsilon greedy. Free: always best.
[181.5275584477757, 177.7040945738698, 183.63038509273431, 179.2680832448184, 178.52439537244913, 180.28207185477578, 179.52312424439805, 182.26248523978728, 180.12492049682604, 178.207800358661]




Conclusion: ignorance of free pulls can increase regrets for epsilon greedy algorithms.



(2) epsilon greedy - adjust epsilon by k
epsilon = 0.2
Normal pulls don't explore at all when k <= 5.
adjusted_epsilon = [          0                             ...                           0         |        0.04       |      0.0667      |      0.0857      |        0.1       |        0.11       ]
k=[    infinity      |        1         |       2          |          3        |          4         |         5        |         6         |        7         |         8        |         9         ]
Normal: epsilon greedy. Free: pure explore.
[237.39443585846274, 103.08380700970696, 112.93983733252823, 117.67530464721067, 116.99656232632272, 143.7438960266488, 154.28757937213012, 167.5880732362403, 172.87699271885742, 184.71124353767945]

Normal: epsilon greedy. Free: always worst.
[237.12816535002716, 127.85042758310715, 130.21469446261298, 133.62577830316965, 132.94286318420995, 150.37866344914175, 162.2626793687505, 177.99807029324217, 179.75226860815172, 187.4083691103349]

Normal: epsilon greedy. Free: always best.
[237.0207640835804, 127.65312467740367, 135.05980350197134, 131.71561017667477, 132.2546865760315, 149.32034521194342, 161.8167331434487, 176.25250382396297, 182.57467898317404, 185.68266390760493]

Normal: epsilon greedy. Free: UCB.
[239.30921258052328, 90.58298709226632, 98.56425120315544, 104.84174382027022, 109.77888075504315, 131.9921520321838, 149.15301124047417, 162.61825027789246, 171.6718041314896, 177.81808088847654]

Normal: epsilon greedy. Free: always real worst, which is arm 0.
[237.76534879445563, 132.00455218094496, 125.17567036156541, 136.00960340557197, 132.6149196658524, 147.22505197599975, 164.04310588811825, 168.98994221197816, 173.36644306685923, 185.76557166427838]

Normal: epsilon greedy. Free: always real best, which is arm 8.
[235.91957976079323, 101.75324989420986, 104.36229841140796, 103.97442059493514, 104.78273547487026, 129.9430470803378, 147.05292323419016, 157.60056947908566, 168.13041493558507, 172.56796262346765]

Normal: epsilon greedy. Free: always real second best, which is arm 7.
[231.72804406856744, 148.64214981920398, 144.52918649976775, 141.3178301790005, 137.54437573573523, 154.76381308958202, 166.44884023895858, 178.51470215364392, 184.16725791259148, 193.80648449050747]



Conclusion: adjusted versions reduce regrets of all tested policies.


2. UCB
(1) Normal: UCB. Free: UCB-E, but don't update confidence
[215.53953970696293, 208.14601155052065, 203.49394878589518, 209.01372879517226, 207.04571791386047, 210.68188101363208, 211.32814169327702, 208.78923131809665, 208.27177940486666, 209.01075559442774]




TODO：
1. free policy: second best UCB arm. Normal: eplison greedy; UCB.
2. solve integral E[x-y]


[0.4, 0.5]

500 trials. Each trial with 500 rounds.
Normal: epsilon greedy. Free: always real second best, which is arm 7.
the average regrets are  [60.43306679252591, 63.53788789984134, 61.30863626444844, 61.66630231432306, 59.05993022007875, 61.298456960997875, 58.445642143770684, 57.528847249622366, 65.93195629339131, 57.67047660876615]
the explore rates are :
[63.56, 436.44]
[63.782, 436.218]
[62.102, 437.898]
[60.996, 439.004]
[61.314, 438.686]
[62.028, 437.972]
[59.606, 440.394]
[61.586, 438.414]
[61.834, 438.166]
[60.354, 439.646]


[0.1...0.9]
500 trials. Each trial with 300 rounds.
Normal: epsilon greedy. Free: always real second best, which is arm 7.
the average regrets are  [386.3057470876223, 393.8607092234293, 386.68197328824147, 392.6336243119184, 391.7179253323563, 392.1689915347778, 384.16585927402696, 390.8674609225589, 388.64540279006644, 391.53995166115135]
the explore rates are :
[7.586, 7.59, 7.578, 7.752, 7.62, 7.702, 9.904, 30.506, 213.762]
[7.378, 7.502, 7.398, 7.484, 7.634, 7.894, 8.642, 44.972, 201.096]
[7.51, 7.526, 7.434, 7.476, 7.708, 7.712, 8.506, 36.758, 209.37]
[7.516, 7.486, 7.468, 7.632, 7.484, 7.61, 8.75, 40.182, 205.872]
[7.452, 7.598, 7.488, 7.372, 7.644, 7.824, 9.186, 39.804, 205.632]
[7.554, 7.634, 7.694, 7.466, 7.562, 8.038, 9.112, 40.996, 203.944]
[7.252, 7.47, 7.568, 7.424, 7.654, 7.79, 8.932, 35.096, 210.814]
[7.462, 7.464, 7.592, 7.554, 7.924, 7.904, 9.168, 37.584, 207.348]
[7.632, 7.576, 7.492, 7.542, 7.572, 7.73, 9.088, 35.802, 209.566]
[7.718, 7.504, 7.056, 7.418, 7.484, 7.974, 9.11, 42.04, 203.696]


500 trials. Each trial with 100 rounds.
Normal: epsilon greedy. Free: always real second best, which is arm 7.
the average regrets are  [153.99020130389744, 152.66343695333097, 157.52273337759146, 153.82376579593006, 157.27310408329276, 154.27414486959904, 155.98860214110542, 155.48868515957884, 156.04275240619558, 153.74821694003663]
the explore rates are :
[3.036, 3.07, 3.016, 3.08, 3.172, 3.534, 5.324, 17.662, 58.106]
[2.864, 3.132, 3.052, 3.1, 3.102, 3.382, 3.878, 19.67, 57.82]
[3.104, 3.024, 3.064, 3.038, 3.102, 3.35, 3.978, 22.46, 54.88]
[3.042, 3.032, 2.998, 3.096, 3.058, 3.324, 4.236, 19.156, 58.058]
[3.06, 3.002, 3.02, 3.178, 3.16, 3.486, 4.308, 21.498, 55.288]
[2.964, 2.962, 3.114, 3.216, 3.022, 3.396, 4.406, 18.184, 58.736]
[3.17, 3.062, 3.104, 3.088, 3.214, 3.266, 4.74, 18.118, 58.238]
[3.124, 3.124, 3.02, 2.994, 3.138, 3.358, 4.43, 18.91, 57.902]
[3.104, 3.04, 3.026, 2.97, 3.116, 3.496, 4.574, 20.41, 56.264]
[3.102, 2.968, 3.042, 3.078, 3.046, 3.448, 4.47, 19.128, 57.718]


10000 trials. Each trial with 100 rounds.
Normal: epsilon greedy. Free: always real second best, which is arm 7.
the average regrets are
[87.43, 87.03, 86.39, 86.79, 86.36, 86.00, 85.77, 85.71, 85.42, 85.77]
the explore rates are :
[1.9981, 2.0089, 2.028, 1.9989, 2.0105, 2.02, 2.236, 8.7299, 76.9697]
[2.0056, 2.0067, 2.0222, 2.0236, 2.0218, 2.0394, 2.1562, 10.3221, 75.4024]
[2.026, 2.0408, 2.0025, 2.0151, 2.0234, 2.0405, 2.1695, 9.7938, 75.8884]
[2.0308, 2.0189, 2.024, 2.0247, 2.0196, 2.038, 2.1685, 8.9675, 76.708]
[2.0063, 2.0252, 2.0116, 2.0323, 2.0198, 2.044, 2.1886, 9.3807, 76.2915]
[2.0258, 2.0077, 2.0214, 2.0318, 2.025, 2.0456, 2.2116, 8.9098, 76.7213]
[2.0172, 2.0237, 2.0246, 2.0195, 2.0261, 2.0342, 2.1985, 8.3616, 77.2946]
[2.0268, 2.0169, 2.0154, 2.0206, 2.0318, 2.0445, 2.1851, 8.3076, 77.3513]
[2.0214, 2.0218, 2.0011, 2.0223, 2.0095, 2.0435, 2.1817, 8.3086, 77.3901]
[2.0122, 2.0298, 2.0123, 2.0193, 2.0302, 2.041, 2.1764, 8.0886, 77.5902]



10000 trials. Each trial with 1000 rounds.
Normal: epsilon greedy. Free: always real second best, which is arm 7.
the average regrets are
[525.53, 524.18, 522.89, 521.99, 522.87, 521.82, 520.92, 522.05, 520.45, 521.08]
the explore rates are :
[11.9908, 11.9603, 12.0619, 12.0424, 12.049, 12.0214, 12.1598, 31.7961, 883.9183]
[12.0601, 12.057, 12.0525, 12.019, 12.0098, 12.0812, 12.0999, 29.7177, 885.9028]
[12.0491, 12.0362, 11.9883, 12.0229, 12.1347, 12.0614, 12.2025, 28.556, 886.9489]
[12.0505, 12.0026, 12.0051, 12.0275, 11.9808, 12.042, 12.168, 28.1063, 887.6172]
[12.0777, 12.0078, 12.1238, 11.9744, 12.0673, 11.9929, 12.2019, 27.6635, 887.8907]
[12.0156, 12.039, 12.0055, 12.0065, 12.0333, 12.0236, 12.2022, 27.4225, 888.2518]
[12.0121, 12.0358, 12.0816, 12.0017, 12.1022, 12.0334, 12.1698, 25.8927, 889.6707]
[12.0079, 12.0613, 12.0271, 12.031, 11.935, 12.0294, 12.1851, 27.4437, 888.2795]
[12.0198, 12.0278, 12.0414, 12.0237, 12.0087, 12.0391, 12.296, 26.3055, 889.238]
[11.977, 12.0074, 12.038, 11.9995, 12.0906, 11.978, 12.2547, 26.9592, 888.6956]



#TODO:
1. none-zero epsilon
2. larger rounds like 100,00. 100,000
3. experiments to prove the proof


1.
(1) Epsilon = 0
st_dev = 0.05
9 arms.

Normal: epsilon greedy. Free: always real second best, which is arm 7.

10000 trials. Each trial with 100 rounds.
the average regrets are
[36.92, 36.67, 36.68, 36.49, 36.6, 36.62, 36.45, 36.64, 36.53, 37.38]

10000 trials. Each trial with 400 rounds.
the average regrets are
[42.14, 41.68, 41.81, 40.88, 41.36, 41.46, 41.25, 40.69, 40.72, 40.56]

10000 trials. Each trial with 1000 rounds.
the average regrets are
[54.56, 52.79, 51.41, 49.71, 48.36, 52.28, 47.39, 49.92, 49.82, 49.35]



(2) 2 arms
Epsilon = 0
st_dev = 0.05

Normal: epsilon greedy. Free: always real second best, which is arm 0.

10000 trials. Each trial with 100 rounds.
the average regrets are
[1.27, 1.24, 1.15, 1.09, 1.09, 1.07, 1.19, 1.15, 1.19, 2.11]

10000 trials. Each trial with 500 rounds.
the average regrets are
[5.18, 4.93, 4.88, 4.26, 4.57, 5.03, 4.31, 4.25, 4.71, 5.12]

10000 trials. Each trial with 1000 rounds.
the average regrets are
[12.1, 8.8, 8.46, 10.42, 8.67, 10.18, 9.58, 8.8, 7.08, 9.47]



Observation:

For real-second-best-arm policy, regrets increase when rounds increase.



2.
(1) UCB second best policy
500 trials. Each trial with 170 rounds.


Normal: epsilon greedy. Free: pure explore.
the average regrets are (k = 1 to infinity - no free pulls)
[218.88, 226.06, 223.73, 226.47, 228.47, 231.08, 231.92, 228.67, 227.46, 238.42]

Normal: epsilon greedy. Free: always worst.
[226.62, 230.31, 234.39, 230.25, 233.26, 234.21, 236.63, 236.85, 233.44, 236.3]

Normal: epsilon greedy. Free: always best.
[225.82, 232.82, 233.84, 234.37, 235.31, 230.33, 234.56, 231.89, 236.21, 237.69]

Normal: epsilon greedy. Free: always real worst, which is arm 0.
[231.94, 230.75, 231.19, 226.57, 234.36, 231.62, 231.06, 232.31, 230.59, 236.0]

Normal: epsilon greedy. Free: always real best, which is arm 8.
[220.77, 220.39, 222.14, 222.6, 222.15, 222.78, 224.12, 225.17, 225.68, 238.91]

Normal: epsilon greedy. Free: always real second best, which is arm 7.
[239.91, 238.54, 241.95, 235.63, 237.55, 238.3, 237.43, 238.67, 239.5, 235.8]

Normal: epsilon greedy. Free: UCB.
[209.36, 212.95, 217.14, 217.33, 223.73, 224.98, 225.69, 223.86, 225.42, 234.94]

#TODO: changed
Normal: epsilon greedy. Free: UCB second best.
[213.61, 216.79, 222.03, 222.07, 226.65, 225.56, 227.94, 227.01, 231.29, 238.56]


(2) UCB as normal pull policy.
same settings

500 trials. Each trial with 170 rounds.
Normal: UCB. Free: pure explore.
[254.62, 321.88, 357.95, 379.62, 391.35, 403.58, 407.82, 413.83, 414.6, 452.55]

Normal: UCB. Free: always worst.
[393.55, 398.21, 402.71, 401.43, 406.11, 404.73, 409.4, 405.37, 408.58, 453.11]

Normal: UCB. Free: always best.
[554.22, 549.44, 525.67, 505.98, 495.57, 490.57, 484.11, 479.09, 476.34, 452.07]

Normal: UCB. Free: always second best.
[470.65, 478.08, 476.58, 475.38, 469.46, 469.21, 466.44, 463.97, 461.55, 450.83]

Normal: UCB. Free: always real worst.
[409.84, 408.48, 407.69, 409.75, 407.1, 410.28, 408.86, 409.46, 408.69, 449.73]

Normal: UCB. Free: always real best.
[554.33, 553.42, 536.14, 518.89, 503.76, 498.03, 490.19, 486.03, 483.03, 451.44]

Normal: UCB. Free: always real second best.
[485.86, 482.9, 484.8, 483.07, 478.95, 473.69, 472.98, 469.58, 465.98, 453.76]

Normal: UCB. Free: UCB second best.
[340.38, 404.83, 420.1, 426.8, 430.74, 431.41, 439.27, 434.76, 439.11, 451.58]

Normal: UCB. Free: epsilon greedy.
[501.55, 503.26, 490.11, 479.04, 472.41, 469.56, 465.14, 462.55, 460.66, 451.8]


Observation:

(a) basically, the more good arms free pulls choose, the worse performance the UCB has.

(b) pure exploration is better than all other policies.

(c) different algorithms are vulnerable to different kinds of free signals.